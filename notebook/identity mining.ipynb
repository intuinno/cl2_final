{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identity Mining \n",
    "\n",
    "We will build identity mining tool for the corpus related to depression. \n",
    "\n",
    "## Dataset \n",
    "\n",
    "First we will start with the MyPersonality dataset with CES-D score. \n",
    "\n",
    "### Data cleaning\n",
    "\n",
    "Let's clean the cesd_item_level.csv.   We will do \n",
    "* Arrange the answers according to the question numbers \n",
    "* Add the total score and verify with 939_userScores.csv \n",
    "* We will filter the data so that it contains only 939 data points, because other points contains invalid value.  \n",
    "\n",
    "In the file “cesd_item_level.csv”, the scores are in the range [1,4], and questions 4, 8, 12 and 16 should be reverse-scored. This means that the CES-D scored should be computed as \n",
    "\n",
    "CES-D = (q1 - 1) + (q2 - 1) + (q3 - 1) + (4 - q4) + (q5 - 1) + …\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(939, 27)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "original = pd.read_csv('../project_materials/mypersonality_depression/cesd_item_level.csv', escapechar='\\\\')\n",
    "cleanScore = pd.read_csv('../project_materials/mypersonality_depression/939_userScores.csv', escapechar='\\\\')\n",
    "\n",
    "original_filtered = pd.DataFrame()\n",
    "\n",
    "\n",
    "for i, row in cleanScore.iterrows():\n",
    "    original_filtered = original_filtered.append( original[(original.userid == row.userid) & (original.time_completed == row.time_completed)]) \n",
    "\n",
    "original_filtered.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "original = original_filtered\n",
    "\n",
    "original.question_order = original.question_order.apply(lambda x: np.fromstring(x, dtype=int, sep=\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %debug\n",
    "\n",
    "for i in range(20):\n",
    "    original['correctOrderQ' + str(i+1)] = 0\n",
    "\n",
    "    \n",
    "for i, row in original.iterrows():\n",
    "    for index in range(row.question_order.shape[0]):\n",
    "#         import ipdb; ipdb.set_trace()\n",
    "        newOrder = 'correctOrderQ' + str(row.question_order[index])\n",
    "        oldValue = 'q' + str(index + 1)\n",
    "        original.loc[i,newOrder] = row[oldValue]\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now we will get the CES-D score\n",
    "original['score'] = 0\n",
    "direction = [ 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, -1, 1, 1, 1, 1 ]\n",
    "for index in range(1,21):\n",
    "    dimName = 'correctOrderQ' + str(index)\n",
    "    original.score = original.score + ( original[dimName] ) * direction[index-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "\n",
    "Let's begin with the simple Histogram of scores.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x10b38d950>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAGjlJREFUeJzt3X+MZfV53/H3x8Yo8Q95TZ3OYnal2SahyaaOljLe0kDD\n",
       "uk0QTiJw6wqblIb1bwnHNqhNu7hVjfoHcSLZ4Y/KrhDYg02hpbaCTFI7LO66dVVhtIQ12GuMaRmV\n",
       "tdldO/Y60CpmCU//uOdmr+bOzJ6zc773e56Zz0sa7T3n3jvns99zz33uec45dxQRmJmZTXpJ7QBm\n",
       "ZjY8Lg5mZjbFxcHMzKa4OJiZ2RQXBzMzm+LiYGZmU4oVB0nbJR2Q9A1JX5f0gWb+TZKOSHqk+XnT\n",
       "xHNulPRtSY9LuqxUNjMzW5tKXecgaSuwNSIOSXol8DDwZuAq4NmI+Niyx+8E7gLeAJwHPACcHxEv\n",
       "FgloZmarKrbnEBFHI+JQc/s54JuM3vQBtMJTrgTujoiTEbEEPAnsLpXPzMxWN5NjDpLmgQuAB5tZ\n",
       "75f0NUm3S9rSzHsdcGTiaUc4VUzMzGyGiheHpqX0WeCDzR7EJ4AdwC7gGeCjazzd3+1hZlbBWSV/\n",
       "uaSXAZ8D7oyIewEi4vjE/bcB9zWT3wG2Tzx9WzNv+e90wTAzOwMRsVJLf9UHF/lhdFzh08AfLJt/\n",
       "7sTtG4C7mts7gUPA2Yz2LP4XzQHzZc+PUpl7/v/fVDvDRsmZIaNzOufQf7q+d5bcc7gYuAZ4VNIj\n",
       "zbwPAVdL2sWoZfQU8N4m9WFJ9wCHgReA66L5HyU1XztAS/O1A7QwXztAS/O1A7Q0XztAS/O1A7Q0\n",
       "XztACcWKQ0T8D1Y+pvGFNZ5zM3BzqUxmZtaOr5AuZ7F2gJYWawdoYbF2gJYWawdoabF2gJYWawdo\n",
       "abF2gBKKXQRXiqSILgdVzMys83un9xwKkbSndoY2MuTMkBGcs2/OWZeLg5mZTXFbycxsE3BbyczM\n",
       "1s3FoZAsfcgMOTNkBOfsm3PW5eJgZmZTfMzBzGwT8DEHMzNbNxeHQrL0ITPkzJARnLNvzlmXi4OZ\n",
       "mU3xMQczs03AxxzMzGzdXBwKydKHzJAzQ0Zwzr45Z10uDmZmNsXHHMzMNgEfczAzs3VzcSgkSx8y\n",
       "Q84MGcE5++acdbk4mJnZFB9zMDPbBHzMwczM1s3FoZAsfcgMOTNkBOfsm3PW5eJgZmZTfMzBzGwT\n",
       "8DEHMzNbNxeHQrL0ITPkzJARnLNvzlmXi4OZmU3xMQezlqTtt8DclnoJjp2IePr6esu3zLq+d55V\n",
       "MozZxjK3BQ4u1Vv+wny9Zdtm47ZSIVn6kBlyZsg4cut87QRtZBlP56zLxcHMzKb4mINZS9LCYu22\n",
       "UsTBvfWWb5n5OgczM1s3F4dCsvQhM+TMkHHExxz65Jx1uTiYmdmUYsVB0nZJByR9Q9LXJX2gmX+O\n",
       "pP2SnpB0v6QtE8+5UdK3JT0u6bJS2WYhIr5cO0MbGXJmyDjynqXaCdrIMp7OWVfJ6xxOAjdExCFJ\n",
       "rwQelrQfeDuwPyJ+X9K/BPYB+yTtBN4K7ATOAx6QdH5EvFgwo3Xgi8DMNo9ixSEijgJHm9vPSfom\n",
       "ozf9K4BLm4fdAXyZUYG4Erg7Ik4CS5KeBHYDD5bKWJKkPRk+UXTLWesisFvnR5/Kh34R2DjnsG3M\n",
       "12Y9WXJ2NZNjDpLmgQuArwJzEXGsuesYMNfcfh1wZOJpRxgVEzMzm7HiX5/RtJQ+B3wwIp6VTp1m\n",
       "GxEhaa0LLVa8T9IisNRMngAOjSv3+MwBT7ebHs9r//jxGTnjT8izmj6VdT3/3/WP11p537NUejz6\n",
       "+v+M1R7PtaYj4stDypNtPJvbe5toS3RU9CI4SS8D/gj4QkTc0sx7HNgTEUclnQsciIifk7QPICI+\n",
       "0jzui8CHI+Kry36nL4KrZLNfBLbZ//+W22AugtNoF+F24PC4MDQ+D1zb3L4WuHdi/tsknS1pB/Cz\n",
       "wEOl8pWW5dznHDlzXD+QJWeOde6ctZVsK10MXAM8KumRZt6NwEeAeyS9k9GuzlUAEXFY0j3AYeAF\n",
       "4LrI9t0eZmYbhL9byVrb7G2Vzf7/t9wG01YyM7O8XBwKydKHzJEzRy8/S84c69w5a3NxMDOzKS4O\n",
       "hWS5YjJHzuFfdTySI2eOde6ctbk4mJnZFBeHQrL0IXPkzNHLz5Izxzp3ztpcHMzMbIqLQyFZ+pA5\n",
       "cubo5WfJmWOdO2dtLg5mZjbFxaGQLH3IHDlz9PKz5Myxzp2zNhcHMzOb4uJQSJY+ZI6cOXr5WXLm\n",
       "WOfOWZuLg5mZTXFxKCRLHzJHzhy9/Cw5c6xz56zNxcHMzKa4OBSSpQ+ZI2eOXn6WnDnWuXPW5uJg\n",
       "ZmZTXBwKydKHzJEzRy8/S84c69w5a3NxMDOzKS4OhWTpQ+bImaOXnyVnjnXunLW5OJiZ2RQXh0Ky\n",
       "9CFz5MzRy8+SM8c6d87aXBzMzGyKi0MhWfqQOXLm6OVnyZljnTtnbS4OZmY2xcWhkCx9yBw5c/Ty\n",
       "s+TMsc6dszYXBzMzm+LiUEiWPmSOnDl6+Vly5ljnzlmbi4OZmU1xcSgkSx8yR84cvfwsOXOsc+es\n",
       "zcXBzMymuDgUkqUPmSNnjl5+lpw51rlz1ubiYGZmU1wcCsnSh8yRM0cvP0vOHOvcOWs7q3YAs/ZO\n",
       "7JYWFust//ndwFK95ZvNTtHiIOmTwK8DxyPi9c28m4B3Ad9rHvahiPhCc9+NwDuAvwQ+EBH3l8xX\n",
       "UpY+ZI6c417+q8+Gg0v1clx4ydr3+5hDn5yzrtJtpU8Bly+bF8DHIuKC5mdcGHYCbwV2Ns/5uCS3\n",
       "vczMKij65hsRXwF+uMJdWmHelcDdEXEyIpaAJ4HdBeMVlaUPmSNnjl5+lpw51rlz1lbrk/n7JX1N\n",
       "0u2StjTzXgccmXjMEeC82UczM7MaxeETwA5gF/AM8NE1HhszSVRAlj5kjpw5evlZcuZY585Z28zP\n",
       "VoqI4+Pbkm4D7msmvwNsn3jotmbeFEmLnDpr5ARwaLyCxrt4ni4zfap1Mn4j9PQsp2uvf0/nmW5u\n",
       "72VkiY4UUfbDuaR54L6Js5XOjYhnmts3AG+IiN9sDkjfxeg4w3nAA8DPxLKAkiIiVjpmMSiS9mT4\n",
       "RNEl5+g00hpnC906P3pzvPAaePjO2S9/7HTLH+csZWE+4uDe9f6WjfjarClRzk7vnaVPZb0buBR4\n",
       "raSngQ8DeyTtYtQyegp4L0BEHJZ0D3AYeAG4bnlhMDOz2ShaHCLi6hVmf3KNx98M3Fwu0exk+CQB\n",
       "WXLm6OVnyZljnTtnbb6OwMzMprg4FJLl3OccOXNcP5AlZ4517py1nbY4SNraXI/wxWZ6p6R3lo9m\n",
       "Zma1tNlzWATuZ3SRGsC3gRtKBdoosvQhc+TM0cvPkjPHOnfO2toUh9dGxH9i9GV4RMRJRmcTmZnZ\n",
       "BtWmODwn6a+NJyRdBPyoXKSNIUsfMkfOHL38LDlzrHPnrK3Nqaz/jNFVzH9D0v8Efgr4x0VTmZlZ\n",
       "VactDhHxsKRfBv4moz2Nx5vWkq0hSx8yR84cvfwsOXOsc+esrc3ZSq8AbgSuj4jHgHlJv1E8mZmZ\n",
       "VdOmrfQp4GHgl5rp7wKfBf6oVKiNINH3rSTIWfo7i/pSOmdffyb1B1vhnKPdnnPsRMTT169/2e3l\n",
       "eG3mydlVm+Lw0xFxlaS3AUTE/5UG/713ZhtQX38m9Va6F7GF+fUv1zJpc7bSjyX95HhC0k8DPy4X\n",
       "aWPI8kkiR84Mew3gnP3K8drMk7OrNnsONwFfBLZJugu4mFPfEW5mZhvQmnsOkl4CvAZ4C/B2Rn9v\n",
       "YSEiDswgW2pZzn3OkTPH9QPO2a8cr808Obtac88hIl6U9C+aK6R9ANrMbJNoc8xhv6R/Lmm7pHPG\n",
       "P8WTJZelD5kjZ44euXP2K8drM0/Ortocc3gbo7/a9r5l83f0H8fMzIbgtHsOETEfETuW/8wiXGZZ\n",
       "+pA5cubokTtnv3K8NvPk7Oq0ew6S3sJoz2HSj4DHIuJ4kVRmZlZVm7bSO4C/CxwABFwK/CmwQ9K/\n",
       "jYhPF8yXVpY+ZI6cOXrkztmvHK/NPDm7alMcXgb8fEQcA5A0B3wG+DvAfwdcHMzMNpg2ZyttHxeG\n",
       "xvFm3p8Bz5eJlV+WPmSOnDl65M7ZrxyvzTw5u2qz53BA0h8D9zBqK70F+HLzba0nSoYzM7M62hSH\n",
       "3wb+EaOvzQC4A/hcRATwxlLBssvSh8yRM0eP3Dn7leO1mSdnV23+2M+Lkg4CP4qI/ZJeDrwSeLZ4\n",
       "OjMzq6LNH/t5D/CfgX/fzNoG3Fsy1EaQpQ+ZI2eOHrlz9ivHazNPzq7aHJB+H3AJ8OcAEfEE8NdL\n",
       "hjIzs7raHHP4cUT8ePwHfiSdxfRFcbZMiT6ktP0WmNvS72+9EGlhb7vHPr8bWOp3+W3k6JE7Z7+y\n",
       "9PKz5OyqTXH4b5L+FfBySb8KXAfcVzaWrWxuSz9/CexMXXhJvWWb2Sy1aSvtA74HPAa8F/gvwL8u\n",
       "GWojyNOHzNB/zpARnLNfWbahLDm7anO20l9Kuhe419+lZGa2Oay656CRmyR9H/gW8C1J35f0YY0P\n",
       "QNiq8vQhM/SfM2QE5+xXlm0oS86u1mor3cDowrc3RMRrIuI1wO5m3g2zCGdmZnWsVRx+C/jNiHhq\n",
       "PCMi/jfwT5r7bA15+pAZ+s8ZMoJz9ivLNpQlZ1drFYezIuJ7y2c289qc5WRmZkmtVRxOnuF9RqY+\n",
       "ZIb+c4aM4Jz9yrINZcnZ1VrF4RclPbvSD/D6Nr9c0iclHZP02MS8cyTtl/SEpPslbZm470ZJ35b0\n",
       "uKTLzvy/ZWZm67FqcYiIl0bEq1b5adtW+hRw+bJ5+4D9EXE+8KVmGkk7gbcCO5vnfFxSm+swBilP\n",
       "HzJD/zlDRnDOfmXZhrLk7Krom29EfAX44bLZVzD62m+af9/c3L4SuDsiTkbEEvAko7OjzMxsxmp8\n",
       "Mp+b+Mtyx4C55vbrgCMTjzsCnDfLYH3K04fM0H/OkBGcs19ZtqEsObuq2rZp/mDQWl/i5y/4MzOr\n",
       "oMYpqcckbY2Io5LOZfQ3qQG+A2yfeNy2Zt4USYuc+nbQE8ChcfUe9/9qT4/n9f37T/WLx5/+1jv9\n",
       "rotg99H+fl+J6Ye2wm0PDifPatOTvfwh5Flt+kzGc2SW29PybWnWy+8wvSsibhlQnsnx29sM4RId\n",
       "afThvRxJ88B9EfH6Zvr3gT+LiN+TtA/YEhH7mgPSdzE6znAe8ADwM7EsoKSIiMF/fYekPX3vbkoL\n",
       "i/1/K+ut8+3bDBdeAw/f2e/y2xhnrLX8sdMtv8tYllh+W2eSc2E+4uDe9S+7vRLbUAmJcnZ67yy6\n",
       "5yDpbuBS4LWSngb+DfAR4B5J72RUza4CiIjDku4BDgMvANctLwyZZHixjGToP2fICM7ZryzbUJac\n",
       "XRUtDhFx9Sp3/coqj78ZuLlcIjMzayPtdQRDl+fc5wznvGfICM7ZryzbUJacXbk4mJnZFBeHQvL0\n",
       "ITP0nzNkBOfsV5ZtKEvOrlwczMxsiotDIXn6kBn6zxkygnP2K8s2lCVnVy4OZmY2xcWhkDx9yAz9\n",
       "5wwZwTn7lWUbypKzKxcHMzOb4uJQSJ4+ZIb+c4aM4Jz9yrINZcnZlYuDmZlNcXEoJE8fMkP/OUNG\n",
       "cM5+ZdmGsuTsysXBzMymuDgUkqcPmaH/nCEjOGe/smxDWXJ25eJgZmZTXBwKydOHzNB/zpARnLNf\n",
       "WbahLDm7cnEwM7MpLg6F5OlDZug/Z8gIztmvLNtQlpxduTiYmdkUF4dC8vQhM/SfM2QE5+xXlm0o\n",
       "S86uXBzMzGyKi0MhefqQGfrPGTKCc/YryzaUJWdXLg5mZjbFxaGQPH3IDP3nDBnBOfuVZRvKkrMr\n",
       "FwczM5vi4lBInj5khv5zhozgnP3Ksg1lydmVi4OZmU1xcSgkTx8yQ/85Q0Zwzn5l2Yay5OzKxcHM\n",
       "zKa4OBSSpw+Zof+cISM4Z7+ybENZcnZ1Vu0AZpbBid3SwuJsl7ljq7Swd3T72ImIp6+f7fI3NxeH\n",
       "QvL0ITP0nzNkhI2d89Vnw8EzeN66TCxvYX7Gy24tz7bejdtKZmY2xcWhkDx9yAz95wwZwTn7liNn\n",
       "nm29GxcHMzOb4uJQSJ4+ZIY+eYaM4Jx9y5Ezz7bejYuDmZlNqVYcJC1JelTSI5IeauadI2m/pCck\n",
       "3S9pS61865WnD5mhr5shIzhn33LkzLOtd1NzzyGAPRFxQUTsbubtA/ZHxPnAl5ppMzObsdptJS2b\n",
       "vgK4o7l9B/Dm2cbpT54+ZIa+boaM4Jx9y5Ezz7beTe09hwckHZT07mbeXEQca24fA+bqRDMz29xq\n",
       "XiF9cUQ8I+mngP2SHp+8MyJCUqz0REmLnLp68gRwaFy9x/2/2tPjeX3//lN92PGnqvVOv+si2H20\n",
       "v99XYvqhrXDbg8PJs9r0ZI98CHlWmz6T8RyrNZ4jQ9m+l03viohbBpRn8r1nbzN0S3SkiBXff2dK\n",
       "0oeB54B3MzoOcVTSucCBiPi5ZY+NiFjejhocSXv63t0cfbdN319hcOt8+933C6+Bh+/sd/ltjDPW\n",
       "Wv7Y6ZbfZSxLLL+tM8lZY+wncy7MRxzcO9vlt1NiWy+h63tnlbaSpJdLelVz+xXAZcBjwOeBa5uH\n",
       "XQvcWyNfHzK8WEYy9HUzZATn7FuOnHm29W5qtZXmgD+UNM7wHyLifkkHgXskvZPRbtBVlfKZmW1q\n",
       "VfYcIuKpiNjV/PytiPjdZv4PIuJXIuL8iLgsIk7UyNeHPOc+ZziXPENGcM6+5ciZZ1vvpvaprGZm\n",
       "NkAuDoXk6UNm6OtmyAjO2bccOfNs6924OJiZ2RQXh0Ly9CEz9HUzZATn7FuOnHm29W5cHMzMbIqL\n",
       "QyF5+pAZ+roZMoJz9i1HzjzbejcuDmZmNsXFoZA8fcgMfd0MGcE5+5YjZ55tvRsXBzMzm+LiUEie\n",
       "PmSGvm6GjOCcfcuRM8+23o2Lg5mZTXFxKCRPHzJDXzdDRnDOvuXImWdb78bFwczMprg4FJKnD5mh\n",
       "r5shIzhn33LkzLOtd+PiYGZmU1wcCsnTh8zQ182QEZyzbzly5tnWu3FxMDOzKS4OheTpQ2bo62bI\n",
       "CM7Ztxw582zr3bg4mJnZlLNqB8hG2n4LzG05/SN/sBXOOdrv0p/fDSz1+ztvnR/+J7QMGcE5+5Yj\n",
       "p6Q9G3HvwcWhs7ktcHDp9I+7lf5f2Bde0u/vMzNbmdtKxQz/E89IhpwZMoJz9i1Hzo241wAuDmZm\n",
       "tgIXh2JynKOdI2eGjOCcfcuR09c5mJnZpuHiUEyOfmmOnBkygnP2LUdOH3MwM7NNw8WhmBz90hw5\n",
       "M2QE5+xbjpwb9ZiDr3MwswRO7JYWFust/9iJiKevr7f82XNxKCZHvzRHzgwZwTn7Npnz1We3u/i0\n",
       "lIX51e7xMQczM9s0XByKydEvzZEzQ0Zwzr7lyOljDmZmm9Zaxzx2bJUW9pZd/uyPeaQsDpJ+ot7S\n",
       "/3bLx2Xs6w5VhozgnH0bUs41j3msNr9Hqx/zKCVlcYBLPl5nucf/Al48u86yzcxmZ3DFQdLlwC3A\n",
       "S4HbIuL3ph/1lf8z41iNX98G32352BzfRZ8jZ4aM4Jx9c86aBnVAWtJLgX8HXA7sBK6W9PN1U52p\n",
       "h7bWTtBOhpwZMoJz9s05axpUcQB2A09GxFJEnAT+I3Bl5Uxn6M8rHhfpIkPODBnBOfvmnDUNrTic\n",
       "Bzw9MX2kmWdmZjM0tGMO0e5h799WNsZqvt/hsd9p8XemhyBDzgwZwTn75pw1KaLl+/EMSLoIuCki\n",
       "Lm+mbwRenDwoLWk4gc3MEokItX3s0IrDWcC3gH/A6LSgh4CrI+KbVYOZmW0yg2orRcQLkn4b+BNG\n",
       "p7Le7sJgZjZ7g9pzMDOzYRja2Up/RdInJR2T9NjEvHMk7Zf0hKT7JVU/ELRKzpskHZH0SPNzec2M\n",
       "Tabtkg5I+oakr0v6QDN/UGO6Rs5Bjamkn5D0VUmHJB2W9LvN/KGN52o5BzWeTaaXNlnua6YHNZZj\n",
       "K+Qc4lguSXq0yfNQM6/TeA62OACfYnQx3KR9wP6IOB/4UjNd20o5A/hYRFzQ/HyxQq7lTgI3RMQv\n",
       "ABcB72suMBzamK6Wc1BjGhF/AbwxInYBvwi8UdIlDGw818g5qPFsfBA4zKmzFgc1lhOW5xziWAaw\n",
       "p8mzu5nXaTwHWxwi4ivAD5fNvgK4o7l9B/DmmYZawSo5AVqfFTALEXE0Ig41t58DvsnoGpJBjeka\n",
       "OWF4Y/r/mptnMzpG9kMGNp6wak4Y0HhK2gb8GnAbp3INbixXySkGNJYTlmfqNJ6DLQ6rmIuIY83t\n",
       "Y8BczTCn8X5JX5N0+1B2h8ckzQMXAF9lwGM6kfPBZtagxlTSSyQdYjRuByLiGwxwPFfJCcMazz8A\n",
       "fgd4cWLe4MaSlXMGwxpLGGV6QNJBSe9u5nUaz2zF4a/E6Ej6UI+mfwLYAewCngE+WjfOKZJeCXwO\n",
       "+GBEPDt535DGtMn5WUY5n2OAYxoRLzbtmm3AL0t647L7BzGeK+Tcw4DGU9JvAMcj4hFW+QQ+hLFc\n",
       "I+dgxnLCxRFxAfAmRq3Zvzd5Z5vxzFYcjknaCiDpXOB45Twriojj0WC0+7n7dM+ZBUkvY1QYPhMR\n",
       "9zazBzemEznvHOcc6pgCRMSPgD8GLmSA4zk2kXNhYOP5S8AVkp4C7gb+vqTPMLyxXCnnpwc2lgBE\n",
       "xDPNv98D/pBRpk7jma04fB64trl9LXDvGo+tphn4sX8IPLbaY2dFkoDbgcMRccvEXYMa09VyDm1M\n",
       "Jb123D6Q9JPArwKPMLzxXDHn+E2iUXU8I+JDEbE9InYAbwP+a0T8UwY2lqvk/K0BvjZfLulVze1X\n",
       "AJc1mbqNZ0QM8odRZf4u8DyjL+N7O3AO8ADwBHA/sGWAOd8BfBp4FPhaswLmBpDzEkZ90kOM3sQe\n",
       "YXSW1aDGdJWcbxramAKvB/60yfko8DvN/KGN52o5BzWeE3kvBT4/xLFclnPPRM7PDGksGbW4DjU/\n",
       "XwduPJPx9EVwZmY2JVtbyczMZsDFwczMprg4mJnZFBcHMzOb4uJgZmZTXBzMzGyKi4OZmU1xcTAz\n",
       "syn/H4wbusEX6KnxAAAAAElFTkSuQmCC\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10b304f10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "original.score.plot(kind='hist', alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use gatherplot for interactive exploration.\n",
    "\n",
    "https://gatherplot-dev.firebaseapp.com/#/ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import dropbox\n",
    "import re\n",
    "import time\n",
    "from firebase import firebase\n",
    "from IPython.display import IFrame\n",
    "\n",
    "def publish_gatherplot(p, dataname):\n",
    "    \n",
    "    filename = str(time.time())+'.csv'\n",
    "    p.index.name = 'indexPandas'\n",
    "    p.to_csv(filename)\n",
    "    access_token = 'vwezSddRAD0AAAAAAAA0K2kAPqcpKnsShlfAPyIxSAYG0l2GxKfx5vtEkSyCeNOk'\n",
    "    client = dropbox.client.DropboxClient(access_token)\n",
    "    f = open(filename,'rb')\n",
    "    response = client.put_file('./gatherplot/' + filename,f)\n",
    "    print \"uploaded:\", response\n",
    "    \n",
    "    response = client.share('./gatherplot/' + filename, short_url=False)\n",
    "    print 'Shared:', response\n",
    "    url = response['url']\n",
    "    match = re.search(r'https://www\\.dropbox\\.com/s/(.+)\\?dl=0', url)\n",
    "    if match:\n",
    "#     print match.group(1)\n",
    "        download_url = 'https://dl.dropboxusercontent.com/s/' + match.group(1)\n",
    "        print download_url\n",
    "        \n",
    "    aFirebase = firebase.FirebaseApplication('https://gatherplot-dev.firebaseio.com',None)\n",
    "    \n",
    "    new_csv = {'name':dataname, \n",
    "           'uploader':\"google:110953151430048855242\", \n",
    "           'uploaderName': \"Deok Gun Park\",\n",
    "           'url': download_url } \n",
    "\n",
    "    result = aFirebase.post('/csv',new_csv)\n",
    "    print result\n",
    "    \n",
    "\n",
    "    return 'https://gatherplot-dev.firebaseapp.com/#/load/' + result['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# url = publish_gatherplot(original, \"CES-D survey exploration - 939 filtered \")\n",
    "url = u'https://gatherplot-dev.firebaseapp.com/#/load/-Jnisp3oVpf5W0h07lRP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"900\"\n",
       "            height=\"1200\"\n",
       "            src=\"https://gatherplot-dev.firebaseapp.com/#/load/-Jnisp3oVpf5W0h07lRP\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x124398690>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(url, 900,1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Open IE \n",
    "\n",
    "We will analyze the result of Open IE. \n",
    "\n",
    "Open IE http://openie.allenai.org/\n",
    "Open IE GitHub https://github.com/knowitall/openie\n",
    "\n",
    "### Depressed Case \n",
    "\n",
    "We ran the reddit depressed.txt file and get the result.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ieDepressed = pd.read_csv('../other_data/ie-depressed_trimmed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64213"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ieDepressed.head()\n",
    "len(ieDepressed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format is not so friendly to process.  Let's try human readable format.  \n",
    "We ran the reddit depressed.txt and get the result as readable-ie-depressed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "\n",
    "f = codecs.open('../other_data/readable-ie-depressed.txt', 'rU', 'utf-8')\n",
    "\n",
    "subject = []\n",
    "relation = []\n",
    "argument = []\n",
    "\n",
    "for line in f:\n",
    "#     print line\n",
    "    match = re.search('(?:Context\\(.*\\):)?\\((.*?);\\s(.*?);\\s(.*?)(?:;.*)*\\)', line)\n",
    "    if match:\n",
    "#         print match.group(3)   ## 'alice-b@google.com' (the whole match)\n",
    "        subject.append(match.group(1).lower())  ## 'alice-b' (the username, group 1)\n",
    "        relation.append(match.group(2).lower())  ## 'google.com' (the host, group 2)\n",
    "        argument.append(match.group(3).lower())  ## 'google.com' (the host, group 2)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* was\n",
      "* is\n",
      "* 'm\n",
      "* feel\n",
      "* have\n",
      "* 's\n",
      "* know\n",
      "* am\n",
      "* to be\n",
      "* want\n",
      "* had\n",
      "* do n't know\n",
      "* think\n",
      "* are\n",
      "* get\n",
      "* got\n",
      "* said\n",
      "* need\n",
      "* do n't want\n",
      "* started\n"
     ]
    }
   ],
   "source": [
    "from nltk import *\n",
    "\n",
    "lemmatizer = stem.WordNetLemmatizer()\n",
    "\n",
    "lemaRelation = [ lemmatizer.lemmatize(word, pos='v') for phrase in relation for word in tokenize.word_tokenize(phrase)]\n",
    "\n",
    "lemaRelationDist = FreqDist(lemaRelation)\n",
    "\n",
    "relationDist = FreqDist(relation)\n",
    "subjectDist = FreqDist(subject)\n",
    "argumentDist = FreqDist(argument)\n",
    "\n",
    "# relationDist.most_common(20)\n",
    "\n",
    "for i,j in relationDist.most_common(20):\n",
    "    print '* '  +  i\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization\n",
    "\n",
    "I tried running lemmatization on the relationship data.  However the data was actually hard to get meaningful insight with lemmatization because it loses the the context like **don't know**.  You can see that **don't know** in the orginal data is replaced with **do** and **n't** in the lemmatized version. \n",
    "\n",
    "##### Top 20 words with lemmatization\n",
    "* be\n",
    "* to\n",
    "* do\n",
    "* n't\n",
    "* have\n",
    "* 'm\n",
    "* want\n",
    "* just\n",
    "* get\n",
    "* feel\n",
    "* know\n",
    "* 've\n",
    "* 's\n",
    "* try\n",
    "* not\n",
    "* go\n",
    "* think\n",
    "* can\n",
    "* ca\n",
    "* make\n",
    "\n",
    "\n",
    "\n",
    "##### Top 20 words without lemmatization \n",
    "\n",
    "* was\n",
    "* is\n",
    "* 'm\n",
    "* feel\n",
    "* have\n",
    "* 's\n",
    "* know\n",
    "* am\n",
    "* to be\n",
    "* want\n",
    "* had\n",
    "* do n't know\n",
    "* think\n",
    "* are\n",
    "* get\n",
    "* got\n",
    "* said\n",
    "* need\n",
    "* do n't want\n",
    "* started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Depressed Case \n",
    "\n",
    "Now I will do same for Non-depressed case.  First I will read the json file format. \n",
    "\n",
    "The raw data is too big in the sense it contains 800MB of text.   I will downsample it with 40MB of text which is 5% of total data.  \n",
    "\n",
    "#### Segment original data into 400kb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import codecs\n",
    "\n",
    "numFiles = 100;\n",
    "\n",
    "for num in range(numFiles):\n",
    "    print num\n",
    "    \n",
    "    fDestination = codecs.open('../project_materials/reddit/segNDepression' + str(num) + '.txt',mode='w',encoding='utf-8')\n",
    "\n",
    "    with codecs.open('../project_materials/reddit/reddit-all-data.out', encoding='utf-8') as fSource:\n",
    "    #       nonDepressed = pd.DataFrame(json.loads(line) for line in f)\n",
    "        for i,line in enumerate(fSource):\n",
    "\n",
    "            if len(line) != 0 and i%2000 == num:\n",
    "    #             print i\n",
    "                a = json.loads(line)\n",
    "                b = a[u'selftext']\n",
    "                fDestination.write(b)\n",
    "        \n",
    "# fSource.close()\n",
    "# fDestination.close()\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the open ie on the segmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "0\n",
      "3\n",
      "1\n",
      "3 command failed: 1\n",
      "4\n",
      "0\n",
      "5\n",
      "0\n",
      "6\n",
      "0\n",
      "7\n",
      "0\n",
      "8\n",
      "0\n",
      "9\n",
      "0\n",
      "10\n",
      "0\n",
      "11\n",
      "0\n",
      "12\n",
      "0\n",
      "13\n",
      "0\n",
      "14\n",
      "0\n",
      "15\n",
      "0\n",
      "16\n",
      "0\n",
      "17\n",
      "0\n",
      "18\n",
      "0\n",
      "19\n",
      "0\n",
      "20\n",
      "0\n",
      "21\n",
      "0\n",
      "22\n",
      "0\n",
      "23\n",
      "0\n",
      "24\n",
      "0\n",
      "25\n",
      "0\n",
      "26\n",
      "0\n",
      "27\n",
      "0\n",
      "28\n",
      "0\n",
      "29\n",
      "0\n",
      "30\n",
      "0\n",
      "31\n",
      "0\n",
      "32\n",
      "0\n",
      "33\n",
      "0\n",
      "34\n",
      "0\n",
      "35\n",
      "0\n",
      "36\n",
      "0\n",
      "37\n",
      "0\n",
      "38\n",
      "0\n",
      "39\n",
      "0\n",
      "40\n",
      "0\n",
      "41\n",
      "0\n",
      "42\n",
      "0\n",
      "43\n",
      "0\n",
      "44\n",
      "0\n",
      "45\n",
      "0\n",
      "46\n",
      "0\n",
      "47\n",
      "0\n",
      "48\n",
      "0\n",
      "49\n",
      "0\n",
      "50\n",
      "0\n",
      "51\n",
      "0\n",
      "52\n",
      "0\n",
      "53\n",
      "0\n",
      "54\n",
      "0\n",
      "55\n",
      "0\n",
      "56\n",
      "0\n",
      "57\n",
      "0\n",
      "58\n",
      "0\n",
      "59\n",
      "0\n",
      "60\n",
      "0\n",
      "61\n",
      "0\n",
      "62\n",
      "0\n",
      "63\n",
      "0\n",
      "64\n",
      "0\n",
      "65\n",
      "0\n",
      "66\n",
      "0\n",
      "67\n",
      "0\n",
      "68\n",
      "0\n",
      "69\n",
      "0\n",
      "70\n",
      "0\n",
      "71\n",
      "0\n",
      "72\n",
      "0\n",
      "73\n",
      "0\n",
      "74\n",
      "0\n",
      "75\n",
      "0\n",
      "76\n",
      "0\n",
      "77\n",
      "0\n",
      "78\n",
      "0\n",
      "79\n",
      "0\n",
      "80\n",
      "0\n",
      "81\n",
      "0\n",
      "82\n",
      "0\n",
      "83\n",
      "0\n",
      "84\n",
      "0\n",
      "85\n",
      "0\n",
      "86\n",
      "0\n",
      "87\n",
      "0\n",
      "88\n",
      "0\n",
      "89\n",
      "0\n",
      "90\n",
      "0\n",
      "91\n",
      "0\n",
      "92\n",
      "0\n",
      "93\n",
      "0\n",
      "94\n",
      "0\n",
      "95\n",
      "0\n",
      "96\n",
      "0\n",
      "97\n",
      "0\n",
      "98\n",
      "0\n",
      "99\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "from multiprocessing.dummy import Pool\n",
    "from subprocess import call\n",
    "import os\n",
    "\n",
    "numFiles = 100\n",
    "\n",
    "os.chdir('/Users/intuinno/codegit/openie/')\n",
    "\n",
    "os.getcwd()\n",
    "\n",
    "numProcess = 4;\n",
    "\n",
    "pool = Pool(numProcess)\n",
    "\n",
    "commands = [ \"sbt 'run-main edu.knowitall.openie.OpenIECli --ignore-errors --split ../cl2_final/project_materials/reddit/segNDepression\" + str(i)  + \".txt ../cl2_final/project_materials/reddit/ie-segNDepression\" + str(i)  + \".txt '\" for i in range(numFiles)] \n",
    "\n",
    "for i, returncode in enumerate(pool.imap(partial(call, shell=True), commands)):\n",
    "    print i\n",
    "    print returncode\n",
    "    if returncode != 0:\n",
    "       print(\"%d command failed: %d\" % (i, returncode))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now combine this data into a single file again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "#### Now combine this data into a single file again.  \n",
    "import codecs\n",
    "\n",
    "os.chdir('/Users/intuinno/codegit/cl2_final/notebook')\n",
    "\n",
    "fDestination  = codecs.open('../project_materials/reddit/ie-NDepression.txt', mode = 'w', encoding='utf-8')\n",
    "\n",
    "for num in range(numFiles):\n",
    "    print num\n",
    "    \n",
    "    fSource = codecs.open('../project_materials/reddit/ie-segNDepression' + str(num) + '.txt',mode='r',encoding='utf-8')\n",
    "\n",
    "#     for i,line in enumerate(fSource):\n",
    "    fDestination.write( fSource.read())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Now Let's run the extraction of tuple for the Non depressed case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "\n",
    "f = codecs.open('../other_data/ie-NDepression.txt', 'rU', 'utf-8')\n",
    "\n",
    "NDsubject = []\n",
    "NDrelation = []\n",
    "NDargument = []\n",
    "\n",
    "for line in f:\n",
    "#     print line\n",
    "    match = re.search('(?:Context\\(.*\\):)?\\((.*?);\\s(.*?);\\s(.*?)(?:;.*)*\\)', line)\n",
    "    if match:\n",
    "#         print match.group(3)   ## 'alice-b@google.com' (the whole match)\n",
    "        NDsubject.append(match.group(1).lower())  ## 'alice-b' (the username, group 1)\n",
    "        NDrelation.append(match.group(2).lower())  ## 'google.com' (the host, group 2)\n",
    "        NDargument.append(match.group(3).lower())  ## 'google.com' (the host, group 2)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "NDtuple = pd.DataFrame({'subject':NDsubject, 'relation':NDrelation, 'argument':NDargument   })\n",
    "NDtuple.to_csv('../other_data/NDtuples.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing KL divergence key contributors.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "1.24351816158e-05\n"
     ]
    }
   ],
   "source": [
    "from nltk import *\n",
    "\n",
    "NDRelDist = FreqDist(NDrelation)\n",
    "NDSubDist = FreqDist(NDsubject)\n",
    "NDArguDist = FreqDist(NDargument)\n",
    "\n",
    "NDRelDist.most_common(50)\n",
    "\n",
    "NDRelDist['is']\n",
    "print relationDist.freq('isA2')\n",
    "\n",
    "laplaceRel = LaplaceProbDist(relationDist)\n",
    "laplaceNDRel = LaplaceProbDist(NDRelDist)\n",
    "\n",
    "print laplaceRel.prob('isA2')\n",
    "\n",
    "klContributionRelDepressedToNonDepressed = {} \n",
    "klContributionRelNonDepressedToDepressed = {}\n",
    "\n",
    "for k in NDRelDist.keys():\n",
    "    klContributionRelDepressedToNonDepressed[k] = laplaceRel.prob(k) * (laplaceRel.logprob(k) - laplaceNDRel.logprob(k))\n",
    "\n",
    "for k in relationDist.keys():\n",
    "    klContributionRelNonDepressedToDepressed[k] = laplaceNDRel.prob(k) * (laplaceNDRel.logprob(k) - laplaceRel.logprob(k))\n",
    "\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "klContributionRelDepressedToNonDepressed\n",
    "\n",
    "import operator\n",
    "\n",
    "sorted_klDepressedToNonDepressed = sorted(klContributionRelDepressedToNonDepressed.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "\n",
    "sorted_klNonDepressedToDepressed = sorted(klContributionRelNonDepressedToDepressed.items(), key=operator.itemgetter(1), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's compare the words that is different from depressed and nondepressed people\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence key contributor from depressed to nondepressed\n",
      "0. feel\n",
      "1. 'm\n",
      "2. do n't know\n",
      "3. was\n",
      "4. hate\n",
      "5. am\n",
      "6. do n't want\n",
      "7. know\n",
      "8. felt\n",
      "9. just feel\n",
      "10. to be\n",
      "11. wish\n",
      "12. feels\n",
      "13. 've been\n",
      "14. do n't know what to do to do\n",
      "15. just want\n",
      "16. do n't feel\n",
      "17. to die\n",
      "18. do\n",
      "19. just need\n",
      "20. told\n",
      "21. 'm not\n",
      "22. just wish\n",
      "23. lost\n",
      "24. try\n",
      "25. started\n",
      "26. wake up\n",
      "27. to talk\n",
      "28. had\n",
      "29. do n't have\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print 'KL Divergence key contributor from depressed to nondepressed'\n",
    "for i in range(30):\n",
    "    print str(i) + '. ' + sorted_klDepressedToNonDepressed[i][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Divergence key contributor from nondepressed to depressed\n",
      "0. is\n",
      "1. are\n",
      "2. has\n",
      "3. 'm looking\n",
      "4. was wondering\n",
      "5. would like\n",
      "6. would be\n",
      "7. used\n",
      "8. have\n",
      "9. looks\n",
      "10. 'd like\n",
      "11. bought\n",
      "12. will be\n",
      "13. use\n",
      "14. to play\n",
      "15. to use\n",
      "16. 're\n",
      "17. looked\n",
      "18. am looking\n",
      "19. says\n",
      "20. like\n",
      "21. saw\n",
      "22. included\n",
      "23. run\n",
      "24. play\n",
      "25. looking\n",
      "26. include\n",
      "27. found\n",
      "28. can get\n",
      "29. plan\n"
     ]
    }
   ],
   "source": [
    "print 'KL Divergence key contributor from nondepressed to depressed'\n",
    "for i in range(30):\n",
    "    print str(i) + '. ' + sorted_klNonDepressedToDepressed[i][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feel | 0.036620430121 | is | 0.0297772352733\n",
      "'m | 0.0211951668249 | are | 0.017229603635\n",
      "do n't know | 0.0108327928574 | has | 0.0064785837501\n",
      "was | 0.00985627614106 | 'm looking | 0.00538325109695\n",
      "hate | 0.00823105700206 | was wondering | 0.00448139125239\n",
      "am | 0.00698328340166 | would like | 0.00370056753597\n",
      "do n't want | 0.00556586136529 | would be | 0.00366413956505\n",
      "know | 0.00473616217423 | used | 0.00349576098803\n",
      "felt | 0.0041754733581 | have | 0.00285251716876\n",
      "just feel | 0.00393774297973 | looks | 0.00281412171106\n",
      "to be | 0.00393379740512 | 'd like | 0.00266112727532\n",
      "wish | 0.0037668237477 | bought | 0.00257892519015\n",
      "feels | 0.00350930165698 | will be | 0.0023917188746\n",
      "'ve been | 0.00344553279076 | use | 0.00233604810325\n",
      "do n't know what to do to do | 0.00328608437846 | to play | 0.00225175131167\n",
      "just want | 0.00325192391721 | to use | 0.00216771632332\n",
      "do n't feel | 0.00292347480345 | 're | 0.00216427755896\n",
      "to die | 0.00258472861186 | looked | 0.0019868497743\n",
      "do | 0.00234496997024 | am looking | 0.00186020227527\n",
      "just need | 0.00232457533705 | says | 0.00162288714766\n",
      "told | 0.00220530714892 | like | 0.00156547427076\n",
      "'m not | 0.00220190139767 | saw | 0.00153061678674\n",
      "just wish | 0.00219190453379 | included | 0.00151216917483\n",
      "lost | 0.00209698332496 | run | 0.00148758905607\n",
      "try | 0.00202329517571 | play | 0.00148171079383\n",
      "started | 0.00197291885473 | looking | 0.00145494111641\n",
      "wake up | 0.00184614958337 | include | 0.00144461132393\n",
      "to talk | 0.00176865571138 | found | 0.00140188467898\n",
      "had | 0.00173806268442 | can get | 0.0013639326444\n",
      "do n't have | 0.00170597871196 | plan | 0.00127646126076\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print sorted_klDepressedToNonDepressed[i][0] + ' | ' + str(sorted_klDepressedToNonDepressed[i][1]) + ' | ' + sorted_klNonDepressedToDepressed[i][0] + ' | ' + str(sorted_klNonDepressedToDepressed[i][1] ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "So here is the comparison of top key differentiators.  \n",
    "\n",
    "Depressed to NonDepressed | KLD score | NonDepressed to Depressed | KLD score\n",
    "------------ | ------------- | ------------ | -------------\n",
    "feel | 0.036620430121 | is | 0.0297772352733\n",
    "'m | 0.0211951668249 | are | 0.017229603635\n",
    "do n't know | 0.0108327928574 | has | 0.0064785837501\n",
    "was | 0.00985627614106 | 'm looking | 0.00538325109695\n",
    "hate | 0.00823105700206 | was wondering | 0.00448139125239\n",
    "am | 0.00698328340166 | would like | 0.00370056753597\n",
    "do n't want | 0.00556586136529 | would be | 0.00366413956505\n",
    "know | 0.00473616217423 | used | 0.00349576098803\n",
    "felt | 0.0041754733581 | have | 0.00285251716876\n",
    "just feel | 0.00393774297973 | looks | 0.00281412171106\n",
    "to be | 0.00393379740512 | 'd like | 0.00266112727532\n",
    "wish | 0.0037668237477 | bought | 0.00257892519015\n",
    "feels | 0.00350930165698 | will be | 0.0023917188746\n",
    "'ve been | 0.00344553279076 | use | 0.00233604810325\n",
    "do n't know what to do to do | 0.00328608437846 | to play | 0.00225175131167\n",
    "just want | 0.00325192391721 | to use | 0.00216771632332\n",
    "do n't feel | 0.00292347480345 | 're | 0.00216427755896\n",
    "to die | 0.00258472861186 | looked | 0.0019868497743\n",
    "do | 0.00234496997024 | am looking | 0.00186020227527\n",
    "just need | 0.00232457533705 | says | 0.00162288714766\n",
    "told | 0.00220530714892 | like | 0.00156547427076\n",
    "'m not | 0.00220190139767 | saw | 0.00153061678674\n",
    "just wish | 0.00219190453379 | included | 0.00151216917483\n",
    "lost | 0.00209698332496 | run | 0.00148758905607\n",
    "try | 0.00202329517571 | play | 0.00148171079383\n",
    "started | 0.00197291885473 | looking | 0.00145494111641\n",
    "wake up | 0.00184614958337 | include | 0.00144461132393\n",
    "to talk | 0.00176865571138 | found | 0.00140188467898\n",
    "had | 0.00173806268442 | can get | 0.0013639326444\n",
    "do n't have | 0.00170597871196 | plan | 0.00127646126076\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The difference 'I' and 'me' usage pattern among the depressed people and nondepressed people.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.549964961458\n",
      "0.34516400597\n"
     ]
    }
   ],
   "source": [
    "print subjectDist.freq('i')\n",
    "print NDSubDist.freq('i')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0298372654364\n",
      "0.0148098605007\n"
     ]
    }
   ],
   "source": [
    "print argumentDist.freq('me')\n",
    "print NDArguDist.freq('me')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# LIWC Analysis\n",
    "\n",
    "Now we will do LIWC analysis.  \n",
    "\n",
    "## Build dictionary\n",
    "\n",
    "I will build the category distribution of LIWC category.  To do that I will begin with liwc.dic file.  \n",
    "\n",
    "From the liwc.dic file, I will extract the category and the words definition.  \n",
    "\n",
    "* **liwc_def** : definition of category\n",
    "* **liwc_words** : the words , and liwc category list tuple. \n",
    "* **getLIWC_Str** : get the string version of the liwc definition for words.  (ex: getLIWC_Str('abandons') returns ['affect', 'negemo', 'sad', 'cogmech', 'inhib'] \n",
    "* **getLIWC_Id** : get the numeric id version of the liwc definition for words. (ex: getLIWC_Id('affect') returns ['131', '133']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['affect', 'negemo', 'sad', 'cogmech', 'inhib']\n",
      "['131', '133']\n",
      "['125', '127', '130', '131', '137']\n",
      "['131', '133']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import fnmatch\n",
    "\n",
    "\n",
    "liwc_def = {}\n",
    "\n",
    "for line in open('../other_data/liwc_defs.txt'):\n",
    "    lineSplit = line.split()\n",
    "    liwc_def[lineSplit[0]] = lineSplit[1]\n",
    "\n",
    "\n",
    "liwc_words = []\n",
    "\n",
    "for line in open('../other_data/liwc_words.txt'):\n",
    "    lineSplit = line.split()\n",
    "    liwc_words.append( (lineSplit[0],  lineSplit[1:len(lineSplit)] ) )\n",
    "\n",
    "liwc_wordsExact = {}\n",
    "liwc_wordsWild = {}\n",
    "\n",
    "for line in open('../other_data/liwc_words.txt'):\n",
    "    lineSplit = line.split()\n",
    "\n",
    "    if lineSplit[0].endswith('*'):\n",
    "        liwc_wordsWild[  lineSplit[0].rstrip('*') ] =   lineSplit[1:len(lineSplit)]\n",
    "    else:\n",
    "        liwc_wordsExact[lineSplit[0]] = lineSplit[1:len(lineSplit)]\n",
    "\n",
    "\n",
    "def getLIWC_Id(w):\n",
    "    for (reExp, catList) in liwc_words:\n",
    "        if fnmatch.fnmatch(w, reExp):\n",
    "            # print w + ' : ' + str(catList)\n",
    "            return catList\n",
    "\n",
    "def getLIWC_Str(w):\n",
    "    for (reExp, catList) in liwc_words:\n",
    "        if fnmatch.fnmatch(w, reExp):\n",
    "            # print w + ' : ' + str(catList)\n",
    "            return [liwc_def[catId] for  catId in catList ]\n",
    "\n",
    "def getLIWC_IdFast(w):\n",
    "        if w in liwc_wordsExact:\n",
    "            # print w + ' : ' + str(catList)\n",
    "            return liwc_wordsExact[w]\n",
    "        else:\n",
    "            for key, value in liwc_wordsWild.iteritems():\n",
    "                if w.startswith(key):\n",
    "                    return value\n",
    "\n",
    "\n",
    "\n",
    "print getLIWC_Str('abandons')\n",
    "print getLIWC_Id('affect')\n",
    "\n",
    "print getLIWC_IdFast('abandons')\n",
    "print getLIWC_IdFast('affect')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's run the code for the depressed case.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "import re\n",
    "from nltk import *\n",
    "\n",
    "f = codecs.open('../project_materials/reddit/depressed.txt', 'rU', 'utf-8')\n",
    "\n",
    "depressedAllText = word_tokenize(f.read())\n",
    "\n",
    "\n",
    "liwcDist = FreqDist()\n",
    "\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "100000\n",
      "110000\n",
      "120000\n",
      "130000\n",
      "140000\n",
      "150000\n",
      "160000\n",
      "170000\n",
      "180000\n",
      "190000\n",
      "200000\n",
      "210000\n",
      "220000\n",
      "230000\n",
      "240000\n",
      "250000\n",
      "260000\n",
      "270000\n",
      "280000\n",
      "290000\n",
      "300000\n",
      "310000\n",
      "320000\n",
      "330000\n",
      "340000\n",
      "350000\n",
      "360000\n",
      "370000\n",
      "380000\n",
      "390000\n",
      "400000\n",
      "410000\n",
      "420000\n",
      "430000\n",
      "440000\n",
      "450000\n",
      "460000\n",
      "470000\n",
      "480000\n",
      "490000\n"
     ]
    }
   ],
   "source": [
    "for (i,w) in enumerate(depressedAllText):\n",
    "    wlower = w.lower()\n",
    "    if i%10000 == 0:\n",
    "        print i\n",
    "    catList =  getLIWC_IdFast(wlower)\n",
    "    if catList:\n",
    "        for cat in catList:\n",
    "            liwcDist[cat] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'1': 263066, '2': 86637, '131': 84862, '11': 65150, '3': 60780, '250': 57242, '17': 53602, '4': 47228, '14': 38707, '12': 35839, ...})"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwcDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we will build a 80MB version of undepressed posts. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import codecs\n",
    "\n",
    "numFiles = 1;\n",
    "\n",
    "for num in range(numFiles):\n",
    "    print num\n",
    "    \n",
    "    fDestination = codecs.open('../project_materials/reddit/nondepressed80MB' + str(num) + '.txt',mode='w',encoding='utf-8')\n",
    "\n",
    "    with codecs.open('../project_materials/reddit/reddit-all-data.out', encoding='utf-8') as fSource:\n",
    "    #       nonDepressed = pd.DataFrame(json.loads(line) for line in f)\n",
    "        for i,line in enumerate(fSource):\n",
    "\n",
    "            if len(line) != 0 and i%10 == num:\n",
    "    #             print i\n",
    "                a = json.loads(line)\n",
    "                b = a[u'selftext']\n",
    "                fDestination.write(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "15\n",
      "0\n",
      "10\n",
      "20\n",
      "25\n",
      "6161112126\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "7172122227\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "8183132328\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "9194142429\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "305055354540\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "315156364641\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "325257374742\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "335358384843\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "345459394944\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "607585658070\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "617686668171\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "627787678272\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "637888688373\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "647989698474\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "9590\n",
      "\n",
      "9691\n",
      "\n",
      "9792\n",
      "\n",
      "9893\n",
      "\n",
      "9994\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-700de086ba39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mpool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocesses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mliwcMPparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mresultDist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/intuinno/anaconda/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    249\u001b[0m         '''\n\u001b[1;32m    250\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mRUN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mimap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/intuinno/anaconda/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/intuinno/anaconda/lib/python2.7/multiprocessing/pool.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    548\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/intuinno/anaconda/lib/python2.7/threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s.wait(): got it\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def liwcMPparse(num):\n",
    "    print num\n",
    "\n",
    "    f = codecs.open('../project_materials/reddit/segNDepression' + str(num) + '.txt',mode='r',encoding='utf-8')\n",
    "\n",
    "    depressedAllText = word_tokenize(f.read())\n",
    "\n",
    "\n",
    "    liwcDist = FreqDist()\n",
    "\n",
    "    for (i,w) in enumerate(depressedAllText):\n",
    "        wlower = w.lower()\n",
    "        catList =  getLIWC_IdFast(wlower)\n",
    "        if catList:\n",
    "            for cat in catList:\n",
    "                liwcDist[cat] += 1\n",
    "\n",
    "    return liwcDist\n",
    "\n",
    "\n",
    "pool = mp.Pool(processes=6)\n",
    "\n",
    "result = pool.map(liwcMPparse, range(100))\n",
    "\n",
    "liwcNDDist = reduce(lambda x, y: x+y, result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "output = open('liwcNDDist.pkl', 'rb')\n",
    "\n",
    "# Pickle dictionary using protocol 0.\n",
    "liwcNDDist = pickle.load(output)\n",
    "\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i | 0.0297223407593 | article | 0.0188451679091\n",
      "ppron | 0.0200478226323 | funct | 0.0121146129348\n",
      "pronoun | 0.0190746365626 | preps | 0.0118820307886\n",
      "negemo | 0.0115120514733 | space | 0.00972325748048\n",
      "sad | 0.00819327062349 | relativ | 0.00943656745716\n",
      "affect | 0.00677807591567 | money | 0.00603035430839\n",
      "health | 0.00474421769244 | leisure | 0.00583158380293\n",
      "bio | 0.00363245390444 | social | 0.00489509464607\n",
      "past | 0.00344426103127 | tentat | 0.00442704103531\n",
      "adverb | 0.0030219613743 | you | 0.00435462688474\n",
      "feel | 0.00290326564529 | see | 0.00415504982348\n",
      "verb | 0.00262749086973 | quant | 0.00373701288603\n",
      "anx | 0.00247461716498 | achieve | 0.00343759263368\n",
      "insight | 0.0024269920569 | incl | 0.00316966835962\n",
      "family | 0.0021878415283 | work | 0.0030210406991\n",
      "time | 0.00206420288525 | posemo | 0.00262936828665\n",
      "present | 0.001796323292 | future | 0.00253504445006\n",
      "negate | 0.00145195699011 | auxverb | 0.0025211185846\n",
      "friend | 0.00144378097066 | we | 0.00245000031214\n",
      "certain | 0.00132255539141 | cogmech | 0.00217265965231\n",
      "anger | 0.00113611303231 | motion | 0.00198018212719\n",
      "swear | 0.000941253493055 | conj | 0.00166383895428\n",
      "death | 0.00078745052477 | number | 0.00158569006813\n",
      "filler | 0.000763096871914 | percept | 0.00141067668628\n",
      "excl | 0.000572189786165 | discrep | 0.00133501658561\n",
      "sexual | 0.000453606382195 | inhib | 0.000834263117877\n",
      "shehe | 0.00023569904543 | relig | 0.000743072070393\n",
      "home | 0.000138698325475 | they | 0.000728530190696\n",
      "humans | 6.94670700563e-05 | cause | 0.000579561156327\n",
      "ipron | -4.71619196513e-05 | ingest | 0.000464977399827\n"
     ]
    }
   ],
   "source": [
    "depressedProbDist = LaplaceProbDist( liwcDist )\n",
    "nondepressedProbDist = LaplaceProbDist(FreqDist(liwcNDDist))\n",
    "\n",
    "klLIWC_D_ND = {} \n",
    "klLIWC_ND_D = {}\n",
    "\n",
    "for k in liwcDist.keys():\n",
    "    klLIWC_D_ND[k] = depressedProbDist.prob(k) * (depressedProbDist.logprob(k) - nondepressedProbDist.logprob(k))\n",
    "\n",
    "for k in liwcNDDist.keys():\n",
    "    klLIWC_ND_D[k] = nondepressedProbDist.prob(k) * (nondepressedProbDist.logprob(k) - depressedProbDist.logprob(k))\n",
    "\n",
    "import operator\n",
    "\n",
    "sorted_klLIWC_D_ND = sorted(klLIWC_D_ND.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "\n",
    "sorted_klLIWC_ND_D = sorted(klLIWC_ND_D.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    \n",
    "for i in range(30):\n",
    "    print liwc_def[sorted_klLIWC_D_ND[i][0]] + ' | ' + str(sorted_klLIWC_D_ND[i][1]) + ' | ' + liwc_def[sorted_klLIWC_ND_D[i][0]] + ' | ' + str(sorted_klLIWC_ND_D[i][1] ) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here is the comparison of top key differentiators.  \n",
    "\n",
    "Depressed to NonDepressed | KLD score | NonDepressed to Depressed | KLD score\n",
    "----------------|---------|-------------|----------------\n",
    "i | 0.0297223407593 | article | 0.0188451679091\n",
    "ppron | 0.0200478226323 | funct | 0.0121146129348\n",
    "pronoun | 0.0190746365626 | preps | 0.0118820307886\n",
    "negemo | 0.0115120514733 | space | 0.00972325748048\n",
    "sad | 0.00819327062349 | relativ | 0.00943656745716\n",
    "affect | 0.00677807591567 | money | 0.00603035430839\n",
    "health | 0.00474421769244 | leisure | 0.00583158380293\n",
    "bio | 0.00363245390444 | social | 0.00489509464607\n",
    "past | 0.00344426103127 | tentat | 0.00442704103531\n",
    "adverb | 0.0030219613743 | you | 0.00435462688474\n",
    "feel | 0.00290326564529 | see | 0.00415504982348\n",
    "verb | 0.00262749086973 | quant | 0.00373701288603\n",
    "anx | 0.00247461716498 | achieve | 0.00343759263368\n",
    "insight | 0.0024269920569 | incl | 0.00316966835962\n",
    "family | 0.0021878415283 | work | 0.0030210406991\n",
    "time | 0.00206420288525 | posemo | 0.00262936828665\n",
    "present | 0.001796323292 | future | 0.00253504445006\n",
    "negate | 0.00145195699011 | auxverb | 0.0025211185846\n",
    "friend | 0.00144378097066 | we | 0.00245000031214\n",
    "certain | 0.00132255539141 | cogmech | 0.00217265965231\n",
    "anger | 0.00113611303231 | motion | 0.00198018212719\n",
    "swear | 0.000941253493055 | conj | 0.00166383895428\n",
    "death | 0.00078745052477 | number | 0.00158569006813\n",
    "filler | 0.000763096871914 | percept | 0.00141067668628\n",
    "excl | 0.000572189786165 | discrep | 0.00133501658561\n",
    "sexual | 0.000453606382195 | inhib | 0.000834263117877\n",
    "shehe | 0.00023569904543 | relig | 0.000743072070393\n",
    "home | 0.000138698325475 | they | 0.000728530190696\n",
    "humans | 6.94670700563e-05 | cause | 0.000579561156327\n",
    "ipron | -4.71619196513e-05 | ingest | 0.000464977399827"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'1': 3669386, '131': 1163550, '2': 954230, '250': 873508, '17': 849720, '11': 842617, '3': 606969, '121': 525939, '12': 509849, '14': 497911, '18': 448738, '10': 439180, '252': 399287, '4': 360932, '125': 356788, '9': 347261, '253': 327797, '16': 323682, '138': 320390, '126': 236701, '135': 234737, '20': 216393, '139': 211155, '13': 205935, '132': 157729, '140': 143026, '134': 132202, '355': 131522, '354': 130493, '251': 120107, '127': 117120, '133': 114532, '146': 101720, '356': 95403, '136': 83463, '7': 81477, '6': 77403, '358': 66781, '19': 64321, '15': 63980, '141': 61578, '21': 51988, '8': 44662, '129': 44250, '5': 42495, '124': 42254, '143': 38722, '147': 37639, '137': 35302, '142': 31609, '148': 30184, '464': 26143, '357': 24829, '130': 22603, '150': 21959, '149': 17893, '128': 17210, '122': 14382, '123': 13897, '359': 12635, '22': 11888, '360': 11625, '462': 10910, '463': 7774})"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liwcNDDist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
